{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions used for preprocessing and cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crp(img):\n",
    "    ht, wd= img.shape\n",
    "    ww = 500\n",
    "    hh = 500\n",
    "    result = np.full((hh,ww), 0, dtype=np.uint8)\n",
    "    xx = (ww - wd) // 2\n",
    "    yy = (hh - ht) // 2\n",
    "    result[yy:yy+ht, xx:xx+wd] = img\n",
    "    final =cv2.resize(result, (50,50))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def countor(input):\n",
    "    img=cv2.imread(input,cv2.IMREAD_GRAYSCALE)\n",
    "    thres=cv2.adaptiveThreshold(img, 255.0, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 51, -20.0)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    out = cv2.erode(thres, kernel)\n",
    "    c,h=cv2.findContours(out, cv2.RETR_EXTERNAL,  cv2.CHAIN_APPROX_SIMPLE)\n",
    "    print(\"Number of items detected: \",len(c))\n",
    "    return c , thres  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating the dierctory and cleaning up image\n",
    "we only train with broken and full rice images, that is mixed rice is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broken\n",
      "broken_grain_1.jpg\n",
      "Number of items detected:  650\n",
      "broken_grain_2.jpg\n",
      "Number of items detected:  526\n",
      "broken_grain_3.jpg\n",
      "Number of items detected:  937\n",
      "full\n",
      "full_grain_1.jpg\n",
      "Number of items detected:  300\n",
      "full_grain_2.jpg\n",
      "Number of items detected:  493\n",
      "full_grain_3.jpg\n",
      "Number of items detected:  680\n",
      "full_grain_4.jpg\n",
      "Number of items detected:  613\n",
      "full_grain_5.jpg\n",
      "Number of items detected:  569\n",
      "full_grain_6.jpg\n",
      "Number of items detected:  619\n",
      "mixed_grains_3.jpg\n",
      "mixed_grain_1.jpg\n",
      "mixed_grain_2.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "for image in  os.listdir():\n",
    "    filename = os.fsdecode(image)\n",
    "    print(filename)\n",
    "    if filename.startswith(\"broken_\"):\n",
    "        if not os.path.exists(\"broken/broken_rice\"):\n",
    "           os.makedirs(\"broken/broken_rice\")\n",
    "        path='broken/broken_rice'\n",
    "        c,thres=countor(image)\n",
    "        nn=1\n",
    "        for i in c:\n",
    "            x, y, width, height = cv2.boundingRect(i)\n",
    "            cimg = thres[y:y+height, x:x+width]\n",
    "            cimg=crp(cimg)\n",
    "            cv2.imwrite(path+str(nn)+\".png\",cimg)\n",
    "            nn=nn+1\n",
    "    elif filename.startswith(\"full_\"):\n",
    "        if not os.path.exists(\"full/full_rice\"):\n",
    "           os.makedirs(\"full/full_rice\")\n",
    "        path='full/full_rice'\n",
    "        c,thres=countor(image)\n",
    "        nn=1\n",
    "        for i in c:\n",
    "            x, y, width, height = cv2.boundingRect(i)\n",
    "            cimg = thres[y:y+height, x:x+width]\n",
    "            cimg=crp(cimg)\n",
    "            cv2.imwrite(path+str(nn)+\".png\",cimg)\n",
    "            nn=nn+1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this will helps to split the labelled preprocessed images into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"train\", output=\"full_split\", seed=1337, ratio=(.8,.2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1293 images belonging to 2 classes.\n",
      "Found 324 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rescale=1. / 255)\n",
    "val_datagen=ImageDataGenerator(rescale=1. / 255)\n",
    "train_data= train_datagen.flow_from_directory(\n",
    "    directory=r\"Downloads\\data\\data\\full_split\\train\",\n",
    "    color_mode='grayscale',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    seed=42\n",
    ")\n",
    "val_data= val_datagen.flow_from_directory(\n",
    "    directory=r\"Downloads\\data\\data\\full_split\\val\",\n",
    "    color_mode='grayscale',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 224, 224, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = next(train_data)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(224,224,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(lr=.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaha\\AppData\\Local\\Temp\\ipykernel_20308\\993764796.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  md = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 25s 2s/step - loss: 0.6351 - accuracy: 0.6656 - val_loss: 0.5094 - val_accuracy: 0.7969\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.5495 - accuracy: 0.7437 - val_loss: 0.3550 - val_accuracy: 0.9219\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.4685 - accuracy: 0.7907 - val_loss: 0.3276 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.4278 - accuracy: 0.8344 - val_loss: 0.5655 - val_accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.3860 - accuracy: 0.8250 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.4508 - accuracy: 0.8040 - val_loss: 0.4591 - val_accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.4227 - accuracy: 0.8272 - val_loss: 0.4583 - val_accuracy: 0.7969\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.4124 - accuracy: 0.8188 - val_loss: 0.3717 - val_accuracy: 0.8125\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.4470 - accuracy: 0.8031 - val_loss: 0.3730 - val_accuracy: 0.8594\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3562 - accuracy: 0.8500 - val_loss: 0.4065 - val_accuracy: 0.8281\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "md = model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=10,\n",
    "    epochs=10,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with the 5 images given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desktop.ini\n",
      "image_1.jpg\n",
      "Number of items detected:  585\n",
      "image_2.jpg\n",
      "Number of items detected:  595\n",
      "image_3.jpg\n",
      "Number of items detected:  595\n",
      "image_4.jpg\n",
      "Number of items detected:  663\n",
      "image_5.jpg\n",
      "Number of items detected:  705\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array \n",
    "import numpy as np\n",
    "fold=1\n",
    "for img in  os.listdir():\n",
    "    filename = os.fsdecode(img)\n",
    "    print(filename)\n",
    "    if filename.startswith(\"ima\"):\n",
    "       if not os.path.exists('test/'+str(fold)):\n",
    "           os.makedirs('test/'+str(fold))\n",
    "       path='test/'+str(fold)+'/'\n",
    "       c,thres=countor(img)\n",
    "       nn=1\n",
    "       for i in c:\n",
    "            x, y, width, height = cv2.boundingRect(i)\n",
    "            cimg = thres[y:y+height, x:x+width]\n",
    "            cimg=crp\n",
    "            (cimg)\n",
    "            cv2.imwrite(path+str(nn)+\".png\",cimg)\n",
    "            nn=nn+1\n",
    "    fold=fold+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "for fil in  os.listdir():\n",
    "   broken=0\n",
    "   full=0\n",
    "   for f in os.listdir(fil):\n",
    "        img = image.load_img(fil+'/'+f, target_size=(224,224), grayscale=True)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        images = np.vstack([x])\n",
    "        classes = model.predict(images)\n",
    "        classes=np.where(classes > 0, 1,0)\n",
    "        if classes == 0:\n",
    "           broken += 1\n",
    "        else:\n",
    "           full += 1\n",
    "   print(\"Total full :\",full)\n",
    "   print(\"Total broken :\",broken)\n",
    "   print('Total : ',full+broken)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c4a9667516ab3510cdc69a21f03234607c83b7b3f032001b192581638fb31e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
